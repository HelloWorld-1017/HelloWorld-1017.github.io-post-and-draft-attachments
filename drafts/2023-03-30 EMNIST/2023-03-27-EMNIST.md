# Introduction

MNIST手写数字数据集是一个典型的图像分类问题的Benchmark，其获取和利用上的便利性使得它在世界范围内的广泛传播，被许多研究者所使用的。整个MNIST数据集相对比较小（与其他的benchmarking datasets相比），并且以非常直接的方式编码和保存：整个编码过程中没有利用复杂的存储结构（storage structures），压缩方式（compression）或者专有的数据格式（proprietary data formats）。因此，使用任何平台或者编程语言都可以很轻松地使用这些数据。但另一方面，随着深度神经网络技术（尤其是卷积神经网络）的发展，许多神经网络结构都能够在MNIST数据集上取得相当高的分类表现；MNIST数据集对于复杂分类任务的代表性是有限的。实际上，MNIST数据集是NIST Special Database 19数据集（其中NIST是National Institute of Standards and Technology，即“美国国家技术标准技术研究所”的缩写）的子集，后者不仅包含手写数字图像，还包含大量的大写字母和小写字母，对应着更复杂的数据分类问题。但是，与MNIST数据集相比，NIST数据集很难获取和使用。

因此，在2017年，Cohen等人 [1] 参考构建MNIST数据集的方式，对NIST Special Database 19重新进行了梳理，将图像数据转换为与MNIST数据集一致的格式，并将其命名为Extended MNIST（EMNIST）（available at: [https://www.westernsydney.edu.au/icns/resources/reproducible_research3/publication_support_materials2/emnist](https://www.westernsydney.edu.au/icns/resources/reproducible_research3/publication_support_materials2/emnist)），并使用ELM-based（Extreme Learning Machine，极限学习机）neural network为EMNIST数据集提供了基准的分类准确率。本博客就主要对论文 [1]  进行学习，并对Cohen等人提供的EMNIST数据集进行初步的整理和分析。

<br>

# NIST Special Database 19, EMNIST

## MNIST Database and NIST Special Database 19

MNIST数据集于1998年由LeCun [2] 等人首次引入，它源自于一个更大的数据集，即NIST Special Database 19 [3]，是后者的一个子集。具体而言，MNIST源自于NIST Special Database 1和NIST Special Database 3的一小部分数字图像（图像处理方式见参考==[XX]==）。NIST Special Database 19是那一系列手写字符数据集的最终版本，本身包含并取代了许多先前发布的手写数据集，例如Special 1,3,7，共包含超过500名书写者所书写的手写数字（digits or numerals）、大写字母（uppercase）和小写字母（lowercase）。NIST Special Database 19代表着一个更大的更复杂的分类任务，以及增加更复杂任务的可能性，例如通过单词解释（words interpretations）进行语义解释（semantic interpretations）。完整的NIST Special Database 19于1995年首次发表 [3]，并于2016年以一种现代的格式重新发布 [4]。

注：NIST数据集的作者和收集者也建议专门使用Special Database 7（同样包含在NIST Special Database 19）中的数据作为测试数据，因为这些样本收集自高中生，这带来了一个更具挑战性的问题（...as the samples were collected from high school students pose a more challenging problem）。
{: .notice--primary}

![image-20230327143030565](https://blogimages-1309804558.cos.ap-nanjing.myqcloud.com/DeLLLaptop/image-20230327143030565.png)

NIST数据集一共包含814,255张图像，旨在提供多种光学字符识别任务（multiple optical character recognition tasks），因此将字符数据呈现在五个独立的数据层次中（five separate data hierarchies）：

- **By_Page**：在收集数据时，书写者被要求填一张标准表格（standard form），一共收集到3699份完整的表格，这些表格就包含了数据的来源。By_Page数据层次中的数据就是这些表格的未处理的二进制图像（unprocessed binary images）。
- **By_Author**：在这个数据层次中，从书写者填写的表格中提取出不同的字符，并且按照不同的书写者打上标签。这个数据层次的数据不利于分类任务，因为每个分组中包含着不同的字符。（This hierarchy contains the segmented character classes organized by writer. It allows for such tasks as writer identification but offers little in the way of classification benefit as each grouping contains digits from multiple classes.）
- **By_Filed**：在这个数据层次中，数据（包括数字和字母）以字段来分类。（This organization contains the digits and character sorted by the field on the collection field in which they appear. This is primarily useful for segmenting digits as they appear in their own isolated fields.）
- **By_Class**：从分类角度讲，这个数据层次是最有用的组织层次。其中的数据按照[0-9]，[a-z]，和[A-Z]分为62个类，并且被分割为数据集和测试集；
- **By_Merge**：这个数据层次解决了在手写数字分类领域的一个有趣的问题，即某些大写字母和小写字母之间的相似性。（This data hierarchy addresses an interesting problem in the classification of handwritten digits, which is the similarity between certain uppercase and lowercase letters.）在依据完整的By_Class的数据层次进行分类时，相似性的影响所导致的识别错误问题在混淆矩阵中非常直观。（**These effects are often plainly visible when examining the confusion matrix resulting from the full classification task on the By Class dataset.**）数据集上的这个变体合并了某些类，创建了一个47类的分类任务。（This variant on the dataset merges certain classes, creating a 47-class classification task.）合并的类包括：C，I，J，K，L，M，O，P，S，U，V，W，X，Y和Z共15个字母。

论文 [1] 所给出的转换过程和所提供的代码适用于所有的数据层次，除了By_Page的数据层次，因为这个数据层次中包含了非常不同的图像。然而，论文 [1] 的工作主要是针对By_Class和By_Merge数据层次，因为它们所对应的分类任务是与标准MNIST数据集一致的。

NIST数据集最初以一种非常高效和紧凑的方式保存，尽管它提供了获取NIST数据集的源代码，但是在现代计算平台上使用这些数据仍然是一件非常困难。因此，NIST最近发布了NIST数据集的第二个版本；然而，NIST数据集仍然以一种原始的方式进行编码。因此，论文 [1] 就提供了一种方式，将NIST Special Database 19转换为与MNIST数据集一致的格式，即构建了EMNIST数据集（即Extended MNIST ）。在使用EMNIST数据集训练神经网络时，研究人员不用调整原本适用于MNIST数据集的网络结构（This is allows the drop-in replacement of the modified NIST datasets without needing to adjust the input layer size or the input range）。EMNIST数据集的目的是在现有的分类系统中替代MNIST数据集。为了替代MNIST数据集，首先需要将目光聚焦在由NIST数据集到MNIST数据集的处理步骤上（the focus of the methodology is on reproducintg the steps used to convert the NIST dataset into the MNIST dataset），并且对整个NIST Special Database 19数据集应用同样的预处理步骤（and apply them to the entire NIST Special Database 19）。

<br>

# Conversion Process

NIST Special Database 19数据集使用了CCITT Group 4 algorithm进行图像的编码和压缩，并且保存在专有的文件格式中。NIST于2016年9月发布了数据集的第二个版本，使用PNG文件格式重新编码了第一版的数据。

论文 [1] 就基于原始数据集提取并转换这些文件：使用预处理技术（post-processing techniques）将NIST数据集中的128x128像素的二进制图像（128x128 pixel binary images）转换为28x28像素的8位灰度图像（28x28 pixel 8-bit grayscale images），以匹配MNIST数据集中的数字图像的特性。其思路与构建MNIST数据集 [2] 大体上是一致的（但是采用不同的下采样技术以处理NIST数据集中字符形状和大小的不同），主要包含四个步骤，如下图所示：

![image-20230328215506844](https://blogimages-1309804558.cos.ap-nanjing.myqcloud.com/imgpersonal/image-20230328215506844.png)

 （1）使用高斯滤波器（$\sigma=1$）柔化字符的边缘；

（2）提取ROI（Region of Interest），使得字符位于图像中央，并且保持纵横比（aspect ratio） 不变；

（3）将图像的左右两边分别padding一个像素，避免字符接触到图像的边缘，最终得到一个正方形的图像；

（4）使用双三次插值算法（bi-cubic interpolation algorithm）将图像下采样至28x28像素的图像，图像数据的取值范围是[0,255]（8-bit range）；

<br>

# Classification Methodology

文章采用了一个简单的三层的极限学习机网络（three-layer ELM network）==[G-B]==。

该神经网络使用两种不同的方式训练。

由于数据集的大小，使得ELM神经网络所需要的伪逆不能在一个step中进行计算（The pseudo-inverse required for the ELM cannot be calculated in a single step due to the size of dataset），网络使用Online Pseudo-Inverse Update Model（OPIUM）[A.Van] 进行计算。该方法迭代地计算输出权重的精确伪逆，使得网络能够处理各种大小的数据集（This method interactively calculates the exact pseudo-inverse solution for the output weights and allows the network to handle datasets of any size）。

所使用的第二种训练方法是OPIUM方法的变体（称为OPIUMLite），其中内部互相关矩阵的计算密集型计算被近似取代，这以精度为代价大大提高了算法的速度。（The second training method used is a variant of the OPIUM method (referred as OPIUMLite) in which the computationally intensive calculation of the internal cross-correlation matrix is replaced by an approximation, which greatly improves the speed of the algorithm at the cost of accuracy.）





下表展示了EMNIST在By_Class和By_Merge数据层次下训练数据和测试数据的分割：

![image-20230328230741920](https://blogimages-1309804558.cos.ap-nanjing.myqcloud.com/imgpersonal/image-20230328230741920.png)

可以看到，在两种不同的数据层次下，都具有814,255条图像数据（包括731,668条测试集数据和82,587条测试数据）。需要注意的是，其中的一半的数据都是digits.



训练了两个ELM-based神经网络；



<br>

# Analysis and Preprocess for EMNIST Database

EMNIST数据集共包含六个`.mat`文件，分别是：`emnist-balanced.mat`，`emnist-byclass.mat`，`emnist-bymerge.mat`，`emnist-digits.mat`，`emnist-letters.mat`，`emnist-mnist.mat`，每个文件存储数据的方式是类似的，下面就主要针对`emnist-balanced.mat`进行详细的分析，其余的`.mat`文件可以用类似的代码进行处理，

## `emnist-balanced.mat`

`emnist-balanced.mat`中只包含一个结构体`dataset`：

```matlab
>> load emnist-balanced.mat
>> whos
  Name         Size                Bytes  Class     Attributes
  dataset      1x1             105282264  struct              
```

该结构体中有三个field：

```matlab
>> dataset
dataset = 
  struct with fields:
      train: [1×1 struct]
       test: [1×1 struct]
    mapping: [47×2 double]
```

`dataset.train`和`dataset.test`结构体中分别保存着训练集和测试集的图像数据，对应的标签和书写者：

```matlab
>> dataset.train
ans = 
  struct with fields:
     images: [112800×784 uint8]
     labels: [112800×1 double]
    writers: [112800×1 double]
```

```matlab
>> dataset.test
ans = 
  struct with fields:
     images: [18800×784 uint8]
     labels: [18800×1 double]
    writers: [18800×1 double]
```

`dataset.mapping`矩阵中则包含着标签与某类事物（不太清楚是什么）的对应关系：

```matlab
>> dataset.mapping
ans =
     0    48
     1    49
     2    50
     ...
    44   113
    45   114
    46   116
```

在了解了数据存储方式后，我们可以写一个简单的脚本对这些数据进行初步的分析和处理，主要包含四个方面：

- 将图像数据以及对应的标签和writer信息从结构体中取出，分析类别的数量，以及训练集和测试集数据中每类样本的数量；
- 将图像数据以4D矩阵（SSCB）的形式进行保存，将标签转换为`categorical`类型的数据，使其更适用于MATLAB分析及后续的神经网络训练；
- 由于在原始的数据集中，图像只是以数据的形式呈现，因此我们在这里将其输出为图像保存，分别保存在`training`和`test`文件夹中（不同类别的图像保存在以类别命名的对应子文件夹中）；
- 将训练集数据和测试集数据保存在`data-balances.mat`文件中；除此之外，在有些情况下， 可能会用到交叉验证方法调整网络参数，因此最后将训练数据和测试数据混合在一起，并将其所有的信息保存在`data-balances.mat`文件中，混合后的数据所对应的图像以类似的方式保存在`merge`文件夹中；

```matlab
clc,clear,close all

load emnist-balanced.mat

% For mapping
mapping = dataset.mapping;

% For training dataset
training_imgs = dataset.train.images;
training_labels = dataset.train.labels;
training_writers = dataset.train.writers;

% For test dataset
test_imgs = dataset.test.images;
test_labels = dataset.test.labels;
test_writers = dataset.test.writers;

% Number of classes
Classes = unique(training_labels);

% Sample size of each class in training dataset
[ClassVariables,~] = findgroups(training_labels);
training_nums = splitapply(@numel,training_labels,ClassVariables);

% Sample size of each class in test dataset
[ClassVariables,~] = findgroups(test_labels);
test_nums = splitapply(@numel,test_labels,ClassVariables);

% Convert data structures of images and labels
training_imgs = reshape(training_imgs',28,28,1,[]);
training_labels = categorical(training_labels);
test_imgs = reshape(test_imgs',28,28,1,[]);
test_labels = categorical(test_labels);

% Save training images
helperSaveImgs("training",training_imgs,training_labels)

% Save test images
helperSaveImgs("test",test_imgs,test_labels)

% Merge the datasets
imgs = cat(4,training_imgs,test_imgs);
labels = [training_labels;test_labels];
writers = [training_writers;test_writers];

% Save all the data
save("data-balances.mat", ...
    "training_imgs","training_labels","training_writers",...
    "test_imgs","test_labels","test_writers",...
    "imgs","labels","writers","mapping")

% Save all the images
helperSaveImgs("merge",imgs,labels)

function helperSaveImgs(datasetName,imgs,labels)
Classes = unique(labels);
for i = 1:numel(Classes)
    mkdir(datasetName,string(Classes(i)))
    idx = labels==Classes(i);
    imgs_perclass = imgs(:,:,:,idx);
    nums = size(imgs_perclass,4);
    for j = 1:nums
        img = imgs_perclass(:,:,1,j);
        imgname = sprintf("%04d.jpg",j);
        filename = fullfile(pwd,datasetName,string(Classes(i)),imgname);
        imwrite(img,filename)
    end
end
end
```

最后可以得到，该数据文件共包含47类图像数据，训练集中每类样本的数量为2,400，测试集中每类样本的数量为400，训练集与测试集的比例均为6。

将数据集混合后每类样本的数量为2,800个，一共131,600条数据：

```matlab
SampleNums = [training_nums,test_nums];

figure("Units","pixels","Position",[80,454,1746,334])
axes
grid(gca,"on")
box(gca,"on")
hold(gca,"on")

b = bar(Classes,SampleNums);
b(1).FaceColor = [7,84,213]/255;
b(2).FaceColor = [249,82,107]/255;

legend("Training","Test")
set(gca,"FontSize",15)
```

![image-20230330211641575](https://blogimages-1309804558.cos.ap-nanjing.myqcloud.com/DeLLLaptop/image-20230330211641575.png)

<br>

## 🙆‍♂️`emnist-byclass.mat`

`emnist-byclass.mat`共包含62类数据，标签与类别的对应关系：



训练集中每类样本的数量为：34585, 38374 (**max**), 34203, 35143, 33535, 31416, 34232, 35754, 33946, 33847, 6407, 3878, 10094, 4562, 4934, 9182, 2517, 3152, 11946, 3762, 2468, 5076, 9002, 8237, 24983, 8347, 2605, 5073, 20764, 9820, 12602, 4637, 4695, 2771, 4743, 2701, 10033, 5159, 2854, 10177, 24631, 2561, 3687, 8738, 2725, 1896 (**min**), 2491, 15318, 2645, 11418, 2749, 2448, 2994, 14105, 2699, 18262, 2830, 2910, 2697, 2822, 2365, 2725；其中，数字图像的样本总量为。。。，大写字母图像的样本总量为。。，小写字母的样本总量为；

测试集中每类样本的数量为：5778, 6330 (**max**), 5869, 5969, 5619, 5190, 5705, 6139, 5633, 5686, 1062, 648, 1739, 779, 851, 1440, 447, 521, 2048, 626, 382, 810, 1485, 1351, 4156, 1397, 413, 809, 3508, 1576, 2002, 796, 806, 432, 798, 464, 1644, 853, 432, 1683, 4092, 400, 589, 1479, 427, 317 (**min**), 466, 2535, 464, 1898, 466, 368, 505, 2320, 437, 2965, 482, 468, 467, 470, 381, 451；其中，数字图像的样本总量为。。。，字母图像的样本总量为。。

训练集与测试集数量之比分别为：5.9856, 6.0622, 5.8277, 5.8876, 5.9681, 6.0532, 6.0004, 5.8241, 6.0263, 5.9527, 6.0330, 5.9846, 5.8045, 5.8562, 5.7979, 6.3764, 5.6309, 6.0499, 5.8330, 6.0096, 6.4607, 6.2667, 6.0620, 6.0970, 6.0113, 5.9749, 6.3075, 6.2707, 5.9190, 6.2310, 6.2947, 5.8254, 5.8251, 6.4144, 5.9436, 5.8211, 6.1028, 6.0481, 6.6065, 6.0469, 6.0193, 6.4025, 6.2598, 5.9080, 6.3817, 5.9811, 5.3455, 6.0426, 5.7004, 6.0158, 5.8991, 6.6522, 5.9287, 6.0797, 6.1762, 6.1592, 5.8714, 6.2179, 5.7752, 6.0043, 6.2073, 6.0421.

![image-20230330211751708](https://blogimages-1309804558.cos.ap-nanjing.myqcloud.com/DeLLLaptop/image-20230330211751708.png)

训练集与测试集混合后，每类样本的数量为：40363, 44704 (**max**), 40072, 41112, 39154, 36606, 39937, 41893, 39579, 39533, 7469, 4526, 11833, 5341, 5785, 10622, 2964, 3673, 13994, 4388, 2850, 5886, 10487, 9588, 29139, 9744, 3018, 5882, 24272, 11396, 14604, 5433, 5501, 3203, 5541, 3165, 11677, 6012, 3286, 11860, 28723, 2961, 4276, 10217, 3152, 2213 (**min**), 2957, 17853, 3109, 13316, 3215, 2816, 3499, 16425, 3136, 21227, 3312, 3378, 3164, 3292, 2746, 3176；其中，数字图像的样本总量为。。。，字母图像的样本总量为。。



一共814,255条图像数据。

## 🙆‍♂️`emnist-bymerge.mat`

`emnist-bymerge.mat`一共包含

标签与类别的对应关系：

训练集中每类样本的数量为：34618, 38304, 34307, 35285, 33656, 31280, 34150, 36020, 33924, 33882, 6411, 3874, 12963, 4606, 4925, 9098, 2534, 3097, 14733, 5689, 4998, 20381, 11612, 8237, 27664, 10748, 2603, 5047, 23509, 9766, 15388, 7588, 7403, 5598, 7092, 5416, 10009, 5080, 10152, 24657, 2535, 3693, 8682, 11444, 2966, 14060, 18248；其中，数字图像的样本总量为。。。，字母图像的样本总量为。。

测试集中每类样本的数量为：5745, 6400, 5765, 5827, 5498, 5326, 5787, 5873, 5655, 5651, 1058, 652, 2156, 735, 860, 1524, 430, 576, 2413, 912, 809, 3358, 1984, 1351, 4690, 1812, 415, 835, 3899, 1630, 2528, 1223, 1262, 897, 1195, 925, 1668, 932, 1708, 4066, 426, 583, 1535, 1872, 533, 2365, 2979；其中，数字图像的样本总量为。。。，字母图像的样本总量为。。

训练集与测试集数量之比分别为：6.0258, 5.9850, 5.9509, 6.0554, 6.1215, 5.8731, 5.9012, 6.1332, 5.9989, 5.9958, 6.0595, 5.9417, 6.0125, 6.2667, 5.7267, 5.9698, 5.8930, 5.3767, 6.1057, 6.2379, 6.1780, 6.0694, 5.8528, 6.0970, 5.8985, 5.9316, 6.2723, 6.0443, 6.0295, 5.9914, 6.0870, 6.2044, 5.8661, 6.2408, 5.9347, 5.8551, 6.0006, 5.4506, 5.9438, 6.0642, 5.9507, 6.3345, 5.6560, 6.1132, 5.5647, 5.9450, 6.1255. 

![image-20230330214158255](https://blogimages-1309804558.cos.ap-nanjing.myqcloud.com/DeLLLaptop/image-20230330214158255.png)

训练集与测试集混合后，每类样本的数量为：40363, 44704, 40072, 41112, 39154, 36606, 39937, 41893, 39579, 39533, 7469, 4526, 15119, 5341, 5785, 10622, 2964, 3673, 17146, 6601, 5807, 23739, 13596, 9588, 32354, 12560, 3018, 5882, 27408, 11396, 17916, 8811, 8665, 6495, 8287, 6341, 11677, 6012, 11860, 28723, 2961, 4276, 10217, 13316, 3499, 16425, 21227；其中，数字图像的样本总量为。。。，字母图像的样本总量为。。

![image-20230331223200597](https://blogimages-1309804558.cos.ap-nanjing.myqcloud.com/imgpersonal/image-20230331223200597.png)

同样有814,255条图像数据。

## `emnist-digits.mat`

![image-20230330214507566](https://blogimages-1309804558.cos.ap-nanjing.myqcloud.com/DeLLLaptop/image-20230330214507566.png)

训练集中每类样本的数量为24,000，测试集中每类样本的数量为4,000，训练集与测试集的比例为6。训练集数据与测试集数据混合后，每类样本有28,000条数据，共有25,2000条数据。

## `emnist-digits.mat`

![image-20230330214648246](https://blogimages-1309804558.cos.ap-nanjing.myqcloud.com/DeLLLaptop/image-20230330214648246.png)

训练集中每类样本的数量都是4,800，测试集中每类样本的数量都是800，训练集与测试集的比例为6。训练集数据与测试集数据混合后，每类样本有5,600条数据，共有145,600条数据。

## `emnist-mnist.mat`

![image-20230331223936361](https://blogimages-1309804558.cos.ap-nanjing.myqcloud.com/imgpersonal/image-20230331223936361.png)

训练集中每类样本的数量都是6,000，测试集中每类样本的数量都是1,000，训练集与测试集的比例为6。训练集数据与测试集数据混合后，每类样本有7,000条数据，共有70,000条数据。

<br>

**References**

[1] G. Cohen, S. Afshar, J. Tapson and A. van Schaik, "EMNIST: Extending MNIST to handwritten letters," *2017 International Joint Conference on Neural Networks (IJCNN)*, Anchorage, AK, USA, 2017, pp. 2921-2926. https://ieeexplore.ieee.org/abstract/document/7966217.

[2] LeCun, Yann, et al. "Gradient-based learning applied to document recognition." *Proceedings of the IEEE* 86.11 (1998): 2278-2324. [MNIST handwritten digit database, Yann LeCun, Corinna Cortes and Chris Burges](http://yann.lecun.com/exdb/mnist/).

[3] Grother, Patrick J. "Nist special database 19-hand-printed forms and characters database." *Technical Report, National Institute of Standards and Technology* (1995). [https://www.nist.gov/system/files/documents/srd/nistsd19.pdf](https://www.nist.gov/system/files/documents/srd/nistsd19.pdf).

[4] Grother, Patrick, and Kayee Hanaoka. "Nist special database 19 handprinted forms and characters 2nd edition." *National Institute of Standards and Technology, Tech. Rep* 13 (2016). 
