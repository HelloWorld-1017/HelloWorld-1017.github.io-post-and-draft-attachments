\documentclass[twocolumn]{article}
\usepackage{amsmath,amsfonts}
\usepackage{algorithm,algpseudocode}

\begin{document}

\begin{algorithm}
\small
\caption{WGAN, our proposed algorithm. All experiments in the paper used the default values $\alpha=0.00005$, $c=0.01$, $m=64$, $n_{\mathrm{critic}}=5$.}\label{alg:cap}
\begin{algorithmic}[1]
\Require $\alpha$, the learning rate. $c$, the clipping parameter. $m$, the batch size. $n_{\text{critic}}$, the number of iterations of the critic per generation iteration.
\Require $w_0$, initial critic parameters. $\theta_0$, initial generator's parameters.
\While{$\theta$ has not converged}
\For{$t=0,\cdots,n_{\text{critic}}$}
\State Sample $\{x^{(i)}\}^m_{i=1}\sim\mathbb{P}_r$ a batch from the real data.
\State Sample $\{z^{(i)}\}^m_{i=1}\sim p(z)$ a batch of priors.
\State $g_w\leftarrow\nabla_w[\frac1m\sum_{i=1}^mf_w(x^{(i)})$

$\hspace{8em}-\frac1m\sum_{i=1}^mf_w(g_\theta(z^{(i)}))]$
\State $w\leftarrow w+\alpha\cdot\text{RMSProp}(w,g_w)$
\State $w\leftarrow\text{clip}(w,-c,c)$
\EndFor
\State Sample $\{z^{(i)}\}^m_{i=1}\sim p(z)$ a batch of prior samples.
\State $g_\theta\leftarrow-\nabla_\theta\frac1m\sum_{i=1}^mf_w(g_\theta(z^{(i)}))$
\State $\theta\leftarrow\theta-\alpha\cdot\text{RMSProp}(\theta,g_\theta)$
\EndWhile
\end{algorithmic}
\end{algorithm}

\end{document}